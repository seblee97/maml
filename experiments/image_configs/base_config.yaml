experiment_name:              
seed:                         0
use_gpu:                      False                            # whether to use a gpu if it is available on the device
resume:
  model:                      
  priority_queue:             
  queue_counts:

task_type:                    omniglot                         # which task to meta-learn e.g. sin- for sinusoid regression
training_iterations:          10000000                         # number of training iterations (total calls to the outer training loop)
task_batch_size:              25                               # number of tasks sampled per meta-update (per outer loop)
meta_lr:                      0.01                             # the base learning rate of the generator (the outer loop optimiser)
inner_update_k:               10                               # number of examples used for inner gradient update (k for k-shot learning)
inner_update_lr:              0.01                             # step size alpha for inner gradient update
num_inner_updates:            1                                # number of inner gradient updates during training
validation_num_inner_updates: 5                                # number of inner gradient updates during fine-tuning in validation/testing
validation_k:                 10                               # number of points given to model during validation step (k for k-shot learning)
test_k:                       10                               # number of points given as test after fine-tuning
validation_task_batch_size:   50                               # number of tasks to sample and evaluate in each validation loop
validation_frequency:         500                              # frequency with which to perform validation during training
visualisation_frequency:      1000                             # frequency with which to perform visualisation of validation (including logging graphs to tb)
visualise_all:                False                            # whether to visualise all updates of test fine-tuning or just final solution
x_dim:                        1                                # dimension of x input 
input_dimension:              [28, 28, 1]                      # dimension of network input (image_wdith, image_height, num_channels)
network_layers:               [64, 64, 64, 64]                 # dimension of layers to be used in network
output_dimension:             1                                # dimension of network output
fixed_validation:             True                             # whether to sample randomly during validation or use fixed structured validation tasks
priority_sample:                                               # whether to use a priority queue in sampling the inner loop task

# task-specific configurations
sin2d:
  domain_bounds:              [-5, 5]                          # domain (x) over which points can be sampled for sin regression
  amplitude_bounds:           [0.1, 5]                         # sample range for amplitude of sine curve to be regressed (max height of sinusoid)
  phase_bounds:               [0, 180]                         # sample range for phase shift of sine curve to be regressed (note will be converted to radians in python)
  fixed_val_blocks:           [0.2, 10]                        # granularity of grid used to generate fixed interval validatio tasks

sin3d:
  domain_bounds:              [-5, 5]                          # domain (x) over which points can be sampled for sin regression
  amplitude_bounds:           [0.1, 5]                         # sample range for amplitude of sine curve to be regressed (max height of sinusoid)
  phase_bounds:               [0, 180]                         # sample range for phase shift of sine curve to be regressed (note will be converted to radians in python)
  frequency_bounds:           [0.5, 2]                         # sample range for frequency squeeze of sine curve to be regressed (note will be converted to radians in python)
  fixed_val_blocks:           [0.2, 10, 0.2]                   # granularity of grid used to generate fixed interval validatio tasks

omniglot:
  data_path:                    /Users/sebastianlee/Dropbox/Documents/Work/Research/maml/data/
  n_train:                      1200                           # number of images to use for training      
  image_output_shape:           [28, 28]                       # shape of downsampled image for training and testing
  examples_per_class:           80                             # number of examples of each class (includes any data augmentation)
  
# priority queue configuration

priority_queue:
  sample_type:                                                 # type of sampling from priority_queue (max, e_greedy, or interpolate)
  epsilon_start:              1.0                              # probability of taking (starting value)
  epsilon_final:              0.1                              # probability of taking (starting value)
  epsilon_decay_start:                                         # training step at which to start epsilon annealing
  epsilon_decay_rate:         0.0000001                        # rate at which to anneal epsilon parameter
  block_sizes_2d:             [0.1, 5]                         # size of block in each dimension of parameter space in which to discretize priority queue
  block_sizes_3d:             [0.1, 5, 0.2]                    # size of block in each dimension of parameter space in which to discretize priority queue
  param_ranges_2d:            [[0.1, 5], [0, 180]]             # range of parameters over whih priority queue is sampled
  param_ranges_3d:            [[0.1, 5], [0, 180], [0.5, 2]]   # range of parameters over whih priority queue is sampled
  burn_in:                                                     # if using argmax without epsilon greedy, need a burn-in to 'fill' priority queue buffer
  initial_value:                                               # value to initialise priority queue elements to  